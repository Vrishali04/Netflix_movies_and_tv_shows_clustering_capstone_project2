{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vrishali04/Netflix_movies_and_tv_shows_clustering_capstone_project2/blob/main/Netflix_Unsupervised_Clustering_Project_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  **Netflix_movies_and_TV_shows_clustering_project**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Netflix_movies_and_TV_shows_clustering_project\n",
        "##### **Contribution**    - TEAM\n",
        "##### **Team Member 1 - <b>PINKY THAKUR</b>\n",
        "##### **Team Member 2 - <b>VRISHALI LATE</b>"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words.\n",
        "\n",
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.\n",
        "\n",
        "If Netflix has been increasingly focusing on TV rather than movies in recent years.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n",
        "https://github.com/Vrishali04/Netflix_movies_and_tv_shows_clustering_capstone_project2"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "<b>This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.</b>"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# To load data from file\n",
        "import pandas as pd \n",
        "\n",
        "# To perform mathemetiacal operations\n",
        "import numpy as np\n",
        "\n",
        "from scipy import stats as st\n",
        "\n",
        "# To visualize data and get insight from the data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# To avoid the warning that aren't necessarily exceptions\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "# Sets the backend of seaborn to the 'inline' backend\n",
        "sns.set()\n",
        "# Sets the backend of matplotlib to the 'inline' backend\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using pandas and read_csv method to load the data\n",
        "path = '/content/drive/MyDrive/Almabetter_Capstone_Projects/Netflix Clustering Unsupervised Capstone Project/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "data = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "43AwG0hE8XAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "#Using the pandas head function \n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "QHLwRK2x8aiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# using pandas columns method\n",
        "\n",
        "print('Columns in our data:')\n",
        "\n",
        "data.columns.tolist()"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using pandas shape method to get the shape of our dataset\n",
        "\n",
        "print('Shape of our dataset : ')\n",
        "data.shape"
      ],
      "metadata": {
        "id": "zHaRYLUv8iLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "data[data.duplicated()].size"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>We can observe here that there is no duplicate rows in the given dataset</b>"
      ],
      "metadata": {
        "id": "mGdtBWdur6WM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Using isnull() from Pandas to get the Null/NaN values in the each column in dataset and \n",
        "# sum() is use to get the sum of missing values present in each column in dataset\n",
        "\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['rating'].replace(np.nan, 'TV-MA',inplace  = True)\n",
        "data['country'].replace(np.nan, 'United States',inplace  = True)"
      ],
      "metadata": {
        "id": "hHe1aNI3sOAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize = (10,5))\n",
        "data.isnull().sum().plot(kind = 'bar')\n",
        "plt.title('Missing Value Visualization')\n",
        "plt.xlabel('columns')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>There are a total of 3631 null values across the entire dataset with 2,389 missing points under “director” 718 under “cast,” 507 under “country,” 10 under “date_added,” and 7 under “rating.”</b>\n",
        "\n",
        "## **We will have to handle all null data points before we can dive into EDA and modeling.**"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['rating'].replace(np.nan, 'TV-MA',inplace  = True)\n",
        "data['country'].replace(np.nan, 'United States',inplace  = True)"
      ],
      "metadata": {
        "id": "NbI7y1JLtfN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cast'].replace(np.nan, 'missing info',inplace  = True)"
      ],
      "metadata": {
        "id": "muBdiiIDthDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['date_added'].notna()]"
      ],
      "metadata": {
        "id": "gd-JAxLytiK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['director'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "hUa-1vqGtjnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "id": "HYIKyQuhtl_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe(include = 'all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# In our dataset there are lots of unique values in lots of columns \n",
        "# Getting the number of unique values present in these columns\n",
        "\n",
        "# Using Dictionary Comprehension to get the dictionary of the columns containing more than 1 unique value\n",
        "\n",
        "unique_count_dict = {column: len(data[column].unique()) for column in data.columns}\n",
        "\n",
        "# Creating seperate list of columns and count from the keys and values of the unique_count_dict\n",
        "\n",
        "column_list = list(unique_count_dict.keys())\n",
        "unique_value_count = list(unique_count_dict.values())\n",
        "\n",
        "# Creating the Dataframe to display the columns and there count of unique values\n",
        "\n",
        "unique_count_df = pd.DataFrame({'Column_name' : column_list, 'Number_of_Unique_Values' : unique_value_count})\n",
        "\n",
        "# Sorting this above unique_count_df in ascending order to get to count of unique values present in each column\n",
        "# Also used reset_index to reset the index and drop the previous index as it was shuffled while sorting values\n",
        "\n",
        "unique_count_df.sort_values(by = ['Number_of_Unique_Values']).reset_index(drop = True)"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Getting the value count for each type using value_counts from pandas\n",
        "data.dtypes"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the date_added column to a datetime format\n",
        "data['date_added'] = pd.to_datetime(data['date_added'])"
      ],
      "metadata": {
        "id": "_Aze-zBOuTrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the year from the date_added column and create a new column called year_added\n",
        "data['year_added'] = data['date_added'].dt.year"
      ],
      "metadata": {
        "id": "lHarUNzFufpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_xM1L7SPuffk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>The year_added column can be useful for analyzing trends: The year_added column, which was derived from the date_added column, can be used to analyze trends in Netflix's content over time. For example, it could be used to determine whether Netflix is adding more content each year, or whether there are certain years where more content is added than others.\n",
        "\n",
        "There is a range of genres represented in the data: The listed_in column shows that Netflix offers content in a variety of genres, including international TV shows, dramas, sci-fi, horror, and action/adventure.</b>"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the value count for each type using value_counts from pandas\n",
        "data['type'].value_counts()"
      ],
      "metadata": {
        "id": "c0ov76SgvIkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Percentage For Response Column\n",
        "(data['type'].value_counts() / data['type'].count()) * 100"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ploting count plot for type column\n",
        "\n",
        "plt.figure(figsize = (8, 4))\n",
        "\n",
        "sns.countplot(data['type'])\n",
        "\n",
        "plt.title('Each type interested for netflix')\n",
        "\n",
        "plt.xlabel('Each type')\n",
        "plt.ylabel('Count for each number of type')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hSrD8F0MvKZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>The chart was chosen to display the distribution of the two types of content (TV Shows and Movies) on Netflix.</b>"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The insight from the chart is that Netflix has more Movies than TV Shows.</b>"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The gained insights could help Netflix in making informed decisions about the type of content they should focus on producing or licensing.</b>"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdirynpwvaXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Getting the year column analysis\n",
        "# Ploting Distribution plot for year \n",
        "plt.figure(figsize = (8, 4))\n",
        "\n",
        "sns.distplot(data['release_year'])\n",
        "\n",
        "plt.title('Each year for release')\n",
        "\n",
        "plt.xlabel('year')\n",
        "plt.ylabel('Count for each Year')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>\n",
        "I picked the distribution plot as it is a great way to visualize the distribution of a continuous variable such as the release_year in this dataset. The distribution plot shows the frequency distribution of the data, with the x-axis representing the values of the variable and the y-axis representing the density or count of the data.\n",
        "</b>"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "**In 2019 has the most numbere of movies and TV Shows are Released.**\n",
        "\n",
        "\n",
        "**In 1977 has the fewest number of movies are realease.**"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "## <b>The insights gained from the distribution plot of release year can help to create a positive business impact for Netflix in several ways. For example:\n",
        "\n",
        "Content planning: By understanding the distribution of release years, Netflix can plan their content strategy to ensure a balance between older and newer content. They can also use this data to identify gaps in their content library and invest in acquiring or producing content to fill those gaps.</b>"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title('Percentage of Netflix Titles that are either Movies or TV Shows')\n",
        "g = plt.pie(data.type.value_counts(),explode=(0.025,0.025), labels=data.type.value_counts().index, colors=['red','green'],autopct='%1.1f%%',startangle=180)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>I picked the specific chart because it is an effective way to visualize the proportion of movies and TV shows in the Netflix library. A pie chart allows us to see the distribution of titles at a glance and compare the proportions of movies and TV shows easily.</b>"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>So there are about 4,000++ Movies and almost 2,000 TV Shows, with movies being the majority.There are far more movie titles (69.1%) that TV shows titles (30.9%) in terms of title.</b>"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>There are no insights from the pie chart that would lead to negative growth for Netflix. However, it is worth noting that the proportion of movies and TV shows in the library may change over time as viewer preferences and trends shift. Therefore, Netflix will need to monitor these trends closely and adjust their content strategy accordingly to ensure continued growth and success.</b>"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "years = list(range(2008,2020,1))\n",
        "movie_rows=data.loc[data[\"type\"] == \"Movie\"]\n",
        "\n",
        "tv_rows=data.loc[data[\"type\"]==\"TV Show\"]\n",
        "\n",
        "movies_counts = movie_rows.year_added.value_counts()\n",
        "tv_counts = tv_rows.year_added.value_counts()\n",
        "\n",
        "index_years_mov = movies_counts.index.isin(years)\n",
        "index_years_tv = tv_counts.index.isin(years)\n",
        "movies = movies_counts[index_years_mov]\n",
        "tv_shows = tv_counts[index_years_tv]"
      ],
      "metadata": {
        "id": "sVKyXAhUw4fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.lineplot(data=movies, color=\"#8B0000\",  label=\"Movies / year\",marker='o')\n",
        "sns.lineplot(data=tv_shows, color=\"#FFC1C1\",  label=\"TV Shows / year\",marker='o')\n",
        "\n",
        "for spine in plt.gca().spines.values():\n",
        "    spine.set_visible(False)\n",
        "\n",
        "plt.grid(color='#E8E8E8', linestyle='--', linewidth=0.7)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left',\n",
        "             borderaxespad=0,frameon=False)\n",
        "\n",
        "\n",
        "plt.xlabel(\"Year Added\")\n",
        "plt.ylabel(\"Numbers\")\n",
        "plt.title('Movies/TV Shows Released')"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "   <b> I picked the specific chart because it allows us to visualize the trend of movies and TV shows released on Netflix over time. The line chart shows the changes in the number of movies and TV shows released each year, making it easy to identify any patterns or trends in the data.</b>"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The insights gained from the line chart include:\n",
        "\n",
        "Overall growth: The chart shows that the number of movies and TV shows added to Netflix has been growing steadily over the years. This indicates that Netflix is continuously adding new content to its library, which can help to retain existing subscribers and attract new ones.\n",
        "\n",
        "Shifts in focus: The chart also shows that the number of TV shows added to Netflix has been growing at a faster rate than movies in recent years. This suggests that Netflix may be shifting its focus towards producing or acquiring more TV shows to meet the changing preferences of its viewers.\n",
        "\n",
        "Seasonal trends: The chart also reveals some seasonal trends, with spikes in the number of movies and TV shows added during certain months or seasons. For example, there appears to be a spike in the number of movies added during the holiday season (December), which could be due to increased demand for family-friendly content during this time.</b>"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n"
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The insights gained from the line chart can help create a positive business impact for Netflix by informing their content acquisition and production strategy. For example, if Netflix sees that TV shows are growing in popularity, they may choose to invest more in producing or acquiring original TV shows to attract and retain subscribers. Additionally, understanding seasonal trends can help Netflix to plan their content releases strategically to maximize viewership and engagement.</b>"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tv_shows = data[data[\"type\"] == \"TV Show\"]\n",
        "movies = data[data[\"type\"] == \"Movie\"]\n",
        "year_counts = data.year_added.value_counts().sort_index()\n",
        "movies_year_counts = movies.year_added.value_counts().sort_index()\n",
        "tv_shows_year_counts = tv_shows.year_added.value_counts().sort_index()"
      ],
      "metadata": {
        "id": "U406SFyUobh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.set(style=\"darkgrid\")\n",
        "\n",
        "tv_show_year_count = tv_shows['release_year'].value_counts().sort_index(ascending=False).head(15)\n",
        "\n",
        "tv_show_year_count.plot(kind ='bar',color = ['orange'])\n",
        "\n",
        "plt.title('Analysis on Release Year of TV Shows', fontsize=15, fontweight='bold')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>The chart shows the analysis of the release year of TV shows, with the top 15 years displayed in a horizontal bar chart. From the chart, it can be seen that the majority of TV shows were released in the year range of 2015-2020, with 2018 having the highest count. This indicates that the period from 2015 to 2020 was a popular time for TV show releases on Netflix.</b>"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "<b>The gained insights can help in making positive business decisions, such as planning the release dates of new TV shows based on popular release years. Additionally, the insights can help in strategizing marketing campaigns for the TV shows based on the trends observed.</b>"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>This is helping us to see the year wise trend of of the tv shows which will make us understand how the the trend changed according to the different years</b>"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_countries = data['country'].value_counts().sort_values(ascending=False).iloc[:15]\n",
        "top_countries\n"
      ],
      "metadata": {
        "id": "xd4HbxydqqqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.set(style=\"darkgrid\")\n",
        "top_countries = data['country'].value_counts().sort_values(ascending=False).iloc[:15]\n",
        "top_countries.plot(kind = 'bar', color = 'purple')\n",
        "\n",
        "plt.title('Analysis of Top 15 Countries by Content Count', fontsize=15, fontweight='bold')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Country')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>I picked the specific chart because it allows us to visualize the trend of movies and TV shows poplarity in different countries</b>"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>Insights:\n",
        "\n",
        "The chart shows the top 15 countries by content count on Netflix.\n",
        "The United States has the highest number of content, followed by India and the United Kingdom.\n",
        "Most of the top countries are English-speaking countries or countries where English is widely spoken, which indicates that Netflix has a significant English-speaking audience.</b>"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>    The gained insights can help Netflix to understand the demand and preferences of their audience in different countries, and allocate resources accordingly.\n",
        "The insights can also help Netflix in creating content that caters to the tastes of their audience in different countries.</b>"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "movie_ratings = data[data['type']=='Movie'].groupby(['rating'])['show_id'].count().reset_index(name = 'count').sort_values(by = 'count', ascending = False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.lineplot(x='rating', y='count', data=movie_ratings, color='steelblue')\n",
        "plt.title('Top Movie Ratings Based On Rating System', fontsize=20)\n",
        "plt.xlabel('Rating', fontsize=15)\n",
        "plt.ylabel('Count', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>The specific chart used is a point plot, which is suitable for comparing the count of different categories within a variable (in this case, movie ratings). It allows for easy visualization of the distribution and comparison of the counts across the ratings.</b>"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The insight gained from the chart is that the most common movie rating on Netflix is TV-MA (Mature Audience Only), followed by TV-14 (Suitable for Ages 14 and Up), and TV-PG (Parental Guidance Suggested). This suggests that Netflix has a lot of content that is not suitable for younger audiences, and that it tends to have more mature content overall.</b>"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The gained insights may help in creating a positive business impact by informing content production decisions and helping to ensure that the content offered aligns with the interests and preferences of the target audience. However, there may be some negative impact if the mature content limits the audience reach or leads to parental concerns about the suitability of the platform for younger viewers. It is important for Netflix to balance its content offerings to appeal to a wide audience while still providing enough mature content to satisfy adult viewers.</b>"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "movie_ratings = data[data['type'] == 'Movie'].groupby(['rating'])['show_id'].count().reset_index(name='movie_count')\n",
        "tv_ratings = data[data['type'] == 'TV Show'].groupby(['rating'])['show_id'].count().reset_index(name='tv_count')\n",
        "\n",
        "merged = pd.merge(movie_ratings, tv_ratings, on='rating')\n",
        "merged = merged.sort_values('movie_count', ascending=False)\n",
        "\n",
        "fig_dims = (12, 8)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "ax.bar(merged['rating'], merged['movie_count'], color='skyblue', label='Movie')\n",
        "ax.bar(merged['rating'], merged['tv_count'], bottom=merged['movie_count'], color='orange', label='TV Show')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Movies and TV Shows by Rating', fontsize=16, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>The distribution of ratings across movies and TV shows. We can easily see which ratings are more common for each type of content, and also the overall distribution of ratings. This can help in making decisions about which ratings to target for new content or marketing campaigns.</b>\n"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>insights can potentially help in creating a positive business impact by providing information on which ratings are most popular among audiences for movies and TV shows.</b>"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>This can help content creators and distributors make decisions about what type of content to produce and what ratings to aim for in order to maximize their audience reach and engagement.</b>"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "fig, ax = plt.subplots(1,2, figsize=(19, 5))\n",
        "g1 = sns.histplot(data=tv_shows, x='rating', kde=False, bins=10, color='purple', ax=ax[0])\n",
        "g1.set_title(\"Distribution of Ratings for TV Shows\")\n",
        "g1.set_xlabel(\"Rating\")\n",
        "g1.set_ylabel(\"Total Count\")\n",
        "g2 = sns.histplot(data=movies, x='rating', kde=False, bins=10, color='purple', ax=ax[1])\n",
        "g2.set(yticks=np.arange(0,1600,200))\n",
        "g2.set_title(\"Distribution of Ratings for Movies\")\n",
        "g2.set_xlabel(\"Rating\")\n",
        "g2.set_ylabel(\"Total Count\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>The code is creating a figure with two subplots, each displaying the count of ratings for either movies or TV shows. The count is represented using a countplot with a color palette of Set2. The x-axis represents the different ratings and the y-axis represents the total count of each rating.</b>"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>ratings for both movies and TV shows. By comparing the count of ratings for both types of content, one can understand which type of content has a higher proportion of a certain rating. The use of different color palettes for each subplot also helps to differentiate between the two types of content being visualized.</b>"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>Overall, this chart can provide insights into the rating distribution for movies and TV shows, which can be used to inform content creation or marketing strategies.</b>"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "top_genres = data['listed_in'].value_counts().sort_values(ascending=False).iloc[:15]\n",
        "sns.barplot(x=top_genres.values, y=top_genres.index, palette='hsv')\n",
        "plt.title('Top 15 Genres in Movies', fontsize=15, fontweight='bold')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Genre')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>I picked the specific chart because it shows the top 15 genres in movies with the corresponding number of movies in each genre in a clear and concise manner using a bar chart.<b>"
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "\n",
        "<b>he insight from the chart is that the most popular genres for movies on the streaming platform are dramas, comedies, and documentaries. Horror, action, and thriller movies are also quite popular, but to a lesser extent.</b>"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The gained insights could help in creating a positive business impact as it can guide the platform in terms of which genres to prioritize when acquiring or producing content. For example, if dramas are the most popular genre, the platform could consider acquiring more dramas to attract and retain viewers who are interested in that genre. However, it's also important to note that these insights are limited to the streaming platform's data and may not be representative of broader industry trends. There are no insights from this chart that lead to negative growth.</b>"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "#Most Occured Word in the titles\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "df_wordcloud = data['title']\n",
        "text = \" \".join(word for word in df_wordcloud)\n",
        "#Create stopword list:\n",
        "\n",
        "stopwords = set(STOPWORDS)\n",
        "#Generate a word cloud image\n",
        "\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "#Use the colormap to color the image\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.margins(x=0, y=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>I have picked this kind of chart because it can provide the isntantand easy inderstatding for the title popularity</b>"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The generated word cloud provides insights into the most commonly occurring words in the titles of the movies and TV shows in the dataset. The larger the word in the cloud, the more frequent the word appeared in the titles.</b>"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The gained insights can help create a positive business impact by providing information about the most common words used in titles. This can inform marketing strategies, such as the use of popular words or themes in promotional material. </b>"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "rating_count = sns.countplot(x='rating', hue='type', data=data, palette='rainbow')\n",
        "\n",
        "ax.set_title('Type and Rating', size=16, fontweight='bold')\n",
        "ax.set_xlabel('Rating')\n",
        "ax.set_ylabel('Count')\n",
        "ax.legend(title='Type')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>The specific chart was chosen to visualize the distribution of content ratings on the streaming platform, grouped by the type of content (movies or TV shows). The countplot is effective in showing the number of occurrences for each rating category.</b>"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The insights gained from the chart include:\n",
        "\n",
        "TV-MA is the most common rating for both movies and TV shows, followed by TV-14 and TV-PG.\n",
        "There are relatively few movies rated NC-17, and no TV shows with this rating.\n",
        "Movies have a higher proportion of G-rated content compared to TV shows.</b>"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>Overall, the gained insights can lead to positive business impacts by helping the platform to make data-driven decisions and offer content that aligns with their audience's preferences. However, there may be potential negative impacts if the platform offers too much of one type of content or rating, which could lead to audience dissatisfaction or loss of viewership.</b>"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year_df = data.year_added.value_counts().to_frame().reset_index().rename(columns={\"index\": \"year\", \"year_added\":\"count\"}).sort_values(by=['year'])\n",
        "movies_year_df = movies.year_added.value_counts().to_frame().reset_index().rename(columns={\"index\": \"year\", \"year_added\":\"count\"}).sort_values(by=['year'])\n",
        "shows_year_df = tv_shows.year_added.value_counts().to_frame().reset_index().rename(columns={\"index\": \"year\", \"year_added\":\"count\"}).sort_values(by=['year'])\n",
        "year_df.sort_values(by=['year'])"
      ],
      "metadata": {
        "id": "bK6_9hLCDr-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "fig, ax = plt.subplots(figsize=(13, 7))\n",
        "\n",
        "movies_line = sns.lineplot(data=movies_year_df, x='year', y='count',color = 'purple')\n",
        "shows_line = sns.lineplot(data=shows_year_df, x='year', y='count',color = 'green')\n",
        "\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Releases')\n",
        "ax.set_title('Total content added across all years (up to 2019)')\n",
        "ax.legend(['Movies', 'TV Shows'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wmduo7FeCifq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>I picked the line chart because it is suitable for displaying trends over time, which is what we are analyzing in this case - the number of movies and TV shows released each year.\n",
        "</b>"
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>The insights gained from this chart can help Netflix make data-driven decisions when it comes to content acquisition and production. For example, they can use this information to allocate resources towards producing more TV shows to meet the growing demand.</b>"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>There are no insights from this chart that lead to negative growth. However, if the trend were to reverse and the number of releases started declining year over year, that would be cause for concern and would require further investigation into the cause.</b>"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['principal_country'] = data['country'].apply(lambda x: x.split(\",\")[0])\n",
        "rating_ages = {'TV-PG': 'Older Kids','TV-MA': 'Adults','TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids','TV-14': 'Young Adults', 'R': 'Adults', 'TV-Y': 'Kids',\n",
        "    'NR': 'Adults', 'PG-13': 'Teens',  'TV-G': 'Kids', 'PG': 'Older Kids', 'G': 'Kids',\n",
        "    'UR': 'Adults',    'NC-17': 'Adults'}\n",
        "data['age_rating'] = data['rating'].replace(rating_ages)\n",
        "# create a new column 'count' with a value of 1 for each row in the dataframe df\n",
        "data['count'] = 1\n",
        "\n",
        "# group the dataframe by 'principal_country', summing the 'count' column and sorting in descending order\n",
        "# then select the top 10 countries and extract only their names\n",
        "top_countries = data.groupby('principal_country')['count'].sum().nlargest(10).index.tolist()\n",
        "\n",
        "# filter the dataframe to keep only the rows where 'principal_country' is in the top 10\n",
        "df_heatmap = data[data['principal_country'].isin(top_countries)]\n",
        "\n",
        "# create a pivot table with 'age_rating' as columns and 'principal_country' as rows,\n",
        "# computing the percentage of each 'age_rating' category within each country\n",
        "df_heatmap = pd.pivot_table(df_heatmap, values='count', index='principal_country', columns='age_rating', aggfunc='sum', fill_value=0)\n",
        "df_heatmap = df_heatmap.div(df_heatmap.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# transpose the table so that 'age_rating' becomes rows and 'principal_country' becomes columns\n",
        "df_heatmap = df_heatmap.T\n"
      ],
      "metadata": {
        "id": "U0N1qVYk1F6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
        "country_order2 = ['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain',\n",
        "       'Mexico']\n",
        "\n",
        "age_order = ['Adults', 'Teens', 'Young Adults', 'Older Kids', 'Kids']\n",
        "\n",
        "sns.heatmap(df_heatmap.loc[age_order,country_order2],cmap=\"jet\",square=True, linewidth=2.5,cbar=False,\n",
        "            annot=True,fmt='2.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":15})\n",
        "\n",
        "ax.spines['top'].set_visible(True)\n",
        "\n",
        "fig.text(.76,.765, 'Target ages proportion of total content by country', fontweight='bold', fontfamily='serif', fontsize=15,ha='right')   \n",
        "\n",
        "ax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=11)\n",
        "ax.set_xticklabels(ax.get_xticklabels(), fontfamily='serif', rotation=90, fontsize=11)\n",
        "\n",
        "ax.set_ylabel('')    \n",
        "ax.set_xlabel('')\n",
        "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "FT6rpzZL1wfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b9Re7f6D1wdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>It picked this because heatmap showing the proportion of content targeted at different age groups in different countries.</b>"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "\n",
        "<b>Insights that can be gleaned from this chart include:\n",
        "\n",
        "The United States has the highest proportion of content targeted at adults, while India has the highest proportion of content targeted at older kids.\n",
        "South Korea has the highest proportion of content targeted at teens, while Mexico has the highest proportion of content targeted at young adults.\n",
        "France has the highest proportion of content targeted at kids.</b>"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,10))\n",
        "sns.pairplot(data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "<b>the given code generates a heatmap using Seaborn library which is a useful way to visualize the proportions of different categories across multiple dimensions.</b>"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here\n",
        "\n",
        "<b>From the chart, one can see the proportion of target ages for the top 10 countries in terms of the number of movies and TV shows available on Netflix. The heatmap shows that the United States has the highest proportion of content for adults and young adults, while India has a higher proportion of content for older kids and teens.</b>"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "l1ZbRNLd2snr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>Already handled the missing data above</b>"
      ],
      "metadata": {
        "id": "RXw8J89b2vWk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>Already handled the missing data above</b>"
      ],
      "metadata": {
        "id": "k3BFUnV0JV4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here.\n",
        "\n",
        "# <b>Already handled the outliers data above</b>"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.copy()\n",
        "df2 = data.copy()\n",
        "\n",
        "# Tokenize the description column using nltk\n",
        "nltk.download('punkt')\n",
        "df2['description'] = df2['description'].apply(lambda x: nltk.word_tokenize(x))\n",
        "\n",
        "# Lowercase and remove non-alphabetic words from the tokenized text\n",
        "df2['description'] = df2['description'].apply(lambda x: [word.lower() for word in x if word.isalpha()])\n",
        "\n",
        "# Join the cleaned text back into sentences\n",
        "df2['description'] = df2['description'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Download the stopwords from nltk\n",
        "nltk.download('stopwords')\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "# Count the number of stopwords\n",
        "print(\"Number of stopwords: \", len(sw))"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of stopwords: \", len(sw))"
      ],
      "metadata": {
        "id": "f-CM9liX-nue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f3fT9nY__Q5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a count vectorizer object\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the count vectorizer using the text data\n",
        "count_vectorizer.fit(df['description'])\n",
        "\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = count_vectorizer.vocabulary_.items()\n",
        "\n",
        "# Create lists to store the vocab and counts\n",
        "vocab = []\n",
        "count = []\n",
        "\n",
        "# Iterate through each vocab and count, append the value to designated lists\n",
        "for key, value in dictionary:\n",
        "    vocab.append(key)\n",
        "    count.append(value)\n",
        "\n",
        "# Store the count in a pandas dataframe with vocab as index\n",
        "vocab_bef_stem = pd.Series(count, index=vocab)\n",
        "\n",
        "# Sort the dataframe\n",
        "vocab_bef_stem = vocab_bef_stem.sort_values()\n",
        "\n",
        "# Plot the top 20 vocab\n",
        "top_vocab = vocab_bef_stem.tail(20)\n",
        "top_vocab.plot(kind='barh', figsize=(5, 10), xlim=(17000, 17500))\n",
        "\n",
        "# Initialize a stemming function using SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "# Define a function for stemming text\n",
        "def stemming(text):\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)\n",
        "\n",
        "# Stem the description column\n",
        "df['description'] = df['description'].apply(lambda x: stemming(x))\n",
        "\n",
        "# Fit the count vectorizer using the stemmed text data\n",
        "count_vectorizer.fit(df['description'])\n",
        "\n",
        "# Collect the vocabulary items used in the vectorizer\n",
        "dictionary = count_vectorizer.vocabulary_.items()\n",
        "\n",
        "# Create lists to store the vocab and counts\n",
        "vocab = []\n",
        "count = []\n",
        "\n",
        "# Iterate through each vocab and count, append the value to designated lists\n",
        "for key, value in dictionary:\n",
        "    vocab.append(key)\n",
        "    count.append(value)\n"
      ],
      "metadata": {
        "id": "Rihtjfac-zM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_vacab = vocab_bef_stem.tail(20)\n",
        "top_vacab.plot(kind = 'bar', figsize=(5,10), color = 'cyan',xlim= (17000, 17500))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u57xb4_g_Vdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the count in a pandas dataframe with vocab as index\n",
        "vocab_after_stem = pd.Series(count, index=vocab)\n",
        "\n",
        "# Sort the dataframe\n",
        "vocab_after_stem = vocab_after_stem.sort_values()\n",
        "\n",
        "# Plot the top 20 vocab\n",
        "top_vocab = vocab_after_stem.tail(20)\n",
        "\n",
        "\n",
        "# Tokenize the description column using nltk\n",
        "df2['description'] = df2['description'].apply(lambda x: nltk.word_tokenize(x))\n",
        "\n",
        "# Lowercase and remove non-alphabetic words from the tokenized text\n",
        "df2['description'] = df2['description'].apply(lambda x: [word.lower() for word in x if word.isalpha()])\n"
      ],
      "metadata": {
        "id": "ajVE4LFb-710"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "R5yiKBIU_LXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lists to store the vocab and counts\n",
        "vocab = []\n",
        "count = []\n",
        "# iterate through each vocab and count append the value to designated lists\n",
        "for key, value in dictionary:\n",
        "    vocab.append(key)\n",
        "    count.append(value)\n",
        "# store the count in panadas dataframe with vocab as index\n",
        "vocab_after_stem = pd.Series(count, index=vocab)\n",
        "# sort the dataframe\n",
        "vocab_after_stem = vocab_after_stem.sort_values()\n",
        "# plot of the top vocab\n",
        "top_vacab = vocab_after_stem.tail(20)"
      ],
      "metadata": {
        "id": "KxA_BIh0_1b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Remove stopwords for listed_in\n",
        "df['listed_in'] = df['listed_in'].apply(lambda x:[word.lower() for word in x.split() if word.lower() not in sw])\n",
        "df['listed_in'] =df['listed_in'].apply(lambda x:\" \".join(x))"
      ],
      "metadata": {
        "id": "4G6D6qwc_uq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create a count vectorizer object\n",
        "count_vectorizer = CountVectorizer()\n",
        "# fit the count vectorizer using the text data\n",
        "count_vectorizer.fit(df['listed_in'])\n",
        "# collect the vocabulary items used in the vectorizer\n",
        "dictionary_l = count_vectorizer.vocabulary_.items()"
      ],
      "metadata": {
        "id": "kw5K_xdb_ihA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lists to store the vocab and counts\n",
        "vocab = []\n",
        "count = []\n",
        "# iterate through each vocab and count append the value to designated lists\n",
        "for key, value in dictionary_l:\n",
        "    vocab.append(key)\n",
        "    count.append(value)\n",
        "# store the count in panadas dataframe with vocab as index\n",
        "vocab_bef_stem = pd.Series(count, index=vocab)\n",
        "# sort the dataframe\n",
        "vocab_bef_stem = vocab_bef_stem.sort_values()"
      ],
      "metadata": {
        "id": "Q_2L6CSn_fnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "metadata": {
        "id": "9z64EQc0AfwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "#nltk.download()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join([char for char in text if char.isalpha() or char == \" \"])\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
        "    #text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "data[\"cleaned_description\"] = data[\"description\"].apply(lambda x: clean_text(x))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NizNL_0CAYQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"description_length\"] = data[\"description\"].apply(lambda x: len(x.split()))\n"
      ],
      "metadata": {
        "id": "3BG5QEe0Abd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(data[\"description_length\"], bins=50)\n",
        "plt.title(\"Distribution of Description Length\")\n",
        "plt.xlabel(\"Description Length\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L8050v14Am9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text = \" \".join(description for description in data.cleaned_description)\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, max_words=200, background_color=\"white\").generate(text)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N8dA4ZkAApN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=5, max_features=5000)\n",
        "\n",
        "tfidf = tfidf_vectorizer.fit_transform(data[\"cleaned_description\"])\n",
        "\n",
        "tfidf = pd.DataFrame(tfidf.todense(), columns=tfidf_vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "iPdE-Fx7uD8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf"
      ],
      "metadata": {
        "id": "CNSGEeERuUyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=5, max_features=5000)\n",
        "\n",
        "tfidf = tfidf_vectorizer.fit_transform(data[\"cleaned_description\"])\n",
        "\n",
        "tfidf = pd.DataFrame(tfidf.todense(), columns=tfidf_vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf"
      ],
      "metadata": {
        "id": "VBRcTjpRySkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ukjWSue_wHHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data['length'] = data['description'].apply(len)"
      ],
      "metadata": {
        "id": "hxE8G03q064Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['length_listed'] = data['listed_in'].apply(len)\n"
      ],
      "metadata": {
        "id": "fyYqIaQ30Ppt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['description','listed_in']]"
      ],
      "metadata": {
        "id": "Asg6E7J_0dnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_features_rec_mon = data[['length', 'length_listed']]\n",
        "scaler_rec_mon = preprocessing.StandardScaler()\n",
        "X_rec_mon = scaler_rec_mon.fit_transform(X_features_rec_mon)\n",
        "\n",
        "range_n_clusters = range(2, 16)\n",
        "silhouette_scores = []\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    kmeans = KMeans(n_clusters=n_clusters)\n",
        "    labels = kmeans.fit_predict(X_rec_mon)\n",
        "    silhouette_avg = silhouette_score(X_rec_mon, labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "    print(f\"For n_clusters = {n_clusters}, the average silhouette score is {silhouette_avg:.4f}\")\n",
        "\n",
        "plt.plot(range_n_clusters, silhouette_scores)\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"Average silhouette score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "# Generate sample data\n",
        "X, _ = make_blobs(n_samples=500, centers=4, random_state=42)\n",
        "\n",
        "# Define range of number of clusters to try\n",
        "range_n_clusters = range(2, 16)\n",
        "\n",
        "# Create subplots for each number of clusters\n",
        "fig, axs = plt.subplots(len(range_n_clusters), 2, figsize=(18, 7 * len(range_n_clusters)))\n",
        "\n",
        "for i, n_clusters in enumerate(range_n_clusters):\n",
        "    # Initialize KMeans clusterer\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "\n",
        "    # Fit data to clusterer\n",
        "    cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "    # Compute silhouette scores for each sample\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    # Set subplot limits\n",
        "    axs[i, 0].set_xlim([-0.1, 1])\n",
        "    axs[i, 0].set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Plot silhouette scores\n",
        "    y_lower = 10\n",
        "    for j in range(n_clusters):\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == j]\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = plt.cm.nipy_spectral(float(j) / n_clusters)\n",
        "        axs[i, 0].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
        "        axs[i, 0].text(-0.05, y_lower + 0.5 * size_cluster_i, str(j))\n",
        "\n",
        "        y_lower = y_upper + 10\n",
        "\n",
        "    # Plot cluster visualization\n",
        "    colors = plt.cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "    axs[i, 1].scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=colors, edgecolor='k')\n",
        "    centers = clusterer.cluster_centers_\n",
        "    axs[i, 1].scatter(centers[:, 0], centers[:, 1], marker='o', c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "    for j, c in enumerate(centers):\n",
        "        axs[i, 1].scatter(c[0], c[1], marker='$%d$' % j, alpha=1, s=50, edgecolor='k')\n",
        "\n",
        "    # Add titles and labels to subplots\n",
        "    axs[i, 0].set_title(\"Silhouette plot for {} clusters\".format(n_clusters))\n",
        "    axs[i, 0].set_xlabel(\"Silhouette coefficient values\")\n",
        "    axs[i, 0].set_ylabel(\"Cluster label\")\n",
        "    axs[i, 0].axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "    axs[i, 1].set_title(\"Cluster visualization for {} clusters\".format(n_clusters))\n",
        "    axs[i, 1].set_xlabel(\"Feature space for the 1st feature\")\n",
        "    axs[i, 1].set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_features_rec_mon = data[['length', 'length_listed']]\n",
        "scaler_rec_mon = preprocessing.StandardScaler()\n",
        "X_rec_mon = scaler_rec_mon.fit_transform(X_features_rec_mon)\n",
        "\n",
        "sum_of_sq_dist = []\n",
        "K = range(1,15)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k, init='k-means++', max_iter=1000)\n",
        "    km = km.fit(X_rec_mon)\n",
        "    sum_of_sq_dist.append(km.inertia_)\n",
        "\n",
        "# plot elbow curve\n",
        "plt.plot(K, sum_of_sq_dist, 'bx-')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Sum of Squared Distances')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X99zr6na2YbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Create a KMeans object with 3 clusters and fit the data\n",
        "y_kmeans = KMeans(n_clusters=3).fit_predict(X)\n"
      ],
      "metadata": {
        "id": "UaQDX_Pf3IiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)\n",
        "y_kmeans = kmeans.predict(X)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15,10))\n",
        "ax.set_title('description and listed_in')\n",
        "scatter = ax.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='spring')\n",
        "centers = kmeans.cluster_centers_\n",
        "ax.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
        "\n",
        "legend1 = ax.legend(*scatter.legend_elements(),\n",
        "                    loc=\"upper right\", title=\"Clusters\")\n",
        "ax.add_artist(legend1)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-9oZ5WxW3Nb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "#set parameters\n",
        "\n",
        "eps = 0.5\n",
        "min_samples = 10\n",
        "#fit DBSCAN model to data\n",
        "\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "y_pred = dbscan.fit_predict(X)\n",
        "#plot the results\n",
        "\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(X[:,0], X[:,1], c=y_pred)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.cluster.hierarchy as sch\n",
        "fig, ax = plt.subplots(figsize=(13,8))\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'), ax=ax)\n",
        "ax.set_title('Dendrogram')\n",
        "ax.set_xlabel('Content')\n",
        "ax.set_ylabel('Euclidean Distances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JNCx2yAV4Hez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
        "y_hc = hc.fit_predict(X)\n",
        "\n",
        "# create a dictionary of cluster labels and their respective colors\n",
        "colors = {0: 'cyan', 1: 'purple', 2: 'orange'}\n",
        "\n",
        "# plot each data point based on its assigned cluster label\n",
        "plt.figure(figsize=(13, 8))\n",
        "for label in set(y_hc):\n",
        "    plt.scatter(X[y_hc == label, 0], X[y_hc == label, 1], s=100, c=colors[label], label=label)\n",
        "\n",
        "plt.title('Clusters of content')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ThxTdnZ75V15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>Conclusions and Inferences</b>\n",
        "\n",
        "<b>In this dataset, there are two types of content: TV shows and movies. TV shows constitute 30.86% of the content, whereas the remaining 69.14% is comprised of movies.\n",
        "\n",
        "The popular streaming platform gained traction after 2014, and since then, the number of content additions has been increasing significantly. This implies that the platform's popularity has been growing over the years, resulting in more content being added.\n",
        "\n",
        "The United States has produced the most amount of content on Netflix, followed by India. This suggests that these two countries are the major contributors to the platform's content.\n",
        "\n",
        "Jan Suter is the most popular director on Netflix, with the highest number of titles, followed by Raul Campos. This implies that these directors have directed the most number of titles on the platform.\n",
        "\n",
        "The top three content categories on Netflix are international movies, dramas, and comedies. This means that these categories are the most popular among the audience.\n",
        "\n",
        "Words such as \"Love\", \"Man\", \"World\", \"Story\", and \"Christmas\" are commonly used in the titles of Netflix's content. The word \"Christmas\" appears frequently in the titles, indicating that many movies with this word in their titles are released in December. Therefore, creating a monthly column can help conclude that more movies with \"Christmas\" in their titles are released in December.\n",
        "\n",
        "The audience prefers TV-MA (adult) and TV-14 (young adults) shows more than other ratings. The least preferred rating is NC-17 (kids), implying that the audience mostly prefers adult-oriented shows.\n",
        "\n",
        "Most of the content watched by the audience is TV-MA (adult), followed by TV-14 (young adults). This suggests that the majority of the audience is mature.\n",
        "\n",
        "In text analysis (NLP), we used stop words, removed punctuations, stemmed words, and applied TF-IDF vectorizer and other NLP functions to analyze the dataset's textual features.\n",
        "\n",
        "We applied different clustering models like KMeans, hierarchical clustering, agglomerative clustering, and DBSCAN to the dataset, and we got the best cluster arrangement.\n",
        "\n",
        "By applying the silhouette score method to the dataset's n range clusters, we obtained the best score, which was 0.3746 for three clusters. This indicates that the content was well-explained in their respective clusters. Additionally, using the elbow method, we determined that k=3 was the best number of clusters to use.</b>"
      ],
      "metadata": {
        "id": "4FggDy8p65P6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}